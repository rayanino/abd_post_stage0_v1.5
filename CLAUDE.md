# CLAUDE.md â€” Arabic Book Digester (ABD)

## What This Is

A pipeline that transforms Shamela HTML exports of classical Arabic books into structured excerpts placed in taxonomy trees. Four sciences: Ø¥Ù…Ù„Ø§Ø¡ (orthography), ØµØ±Ù (morphology), Ù†Ø­Ùˆ (syntax), Ø¨Ù„Ø§ØºØ© (rhetoric). The excerpts feed a future synthesis LLM that produces encyclopedia entries.

## Pipeline Stages

| Stage | Tool | Status | Tests |
|-------|------|--------|-------|
| 0 Intake | `tools/intake.py` | âœ… Complete | `tests/test_intake.py` |
| 1 Normalization | `tools/normalize_shamela.py` | âœ… Complete | `tests/test_normalization.py` |
| 2 Structure Discovery | `tools/discover_structure.py` | âœ… Complete | `tests/test_structure_discovery.py` |
| 3+4 Extraction | `tools/extract_passages.py` | ğŸŸ¡ Vertical slice done | Needs tests |
| 5 Taxonomy Placement | (implicit in Stage 3+4) | ğŸŸ¡ Basic | â€” |
| 6 Synthesis | â€” | â¬œ Not started | â€” |

## Running Things

```bash
# Tests (389 pass, ~20s)
python -m pytest tests/ -q

# Single test file
python -m pytest tests/test_structure_discovery.py -q

# Extraction dry run (no API needed)
python tools/extract_passages.py \
  --passages /path/to/passages.jsonl \
  --pages /path/to/pages.jsonl \
  --taxonomy taxonomy/imlaa_v0.1.yaml \
  --book-id qimlaa --book-title "Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¡" --science imlaa \
  --output-dir /tmp/output --dry-run

# Extraction with API
export ANTHROPIC_API_KEY="sk-ant-..."
# Same command without --dry-run
```

## Dependencies

```bash
pip install PyYAML httpx
```

Python 3.11+ required. No virtual env needed for simple runs; use `pip install --break-system-packages` if on system Python.

## Key Files to Read

**Start here (in order):**
1. This file
2. `REPO_MAP.md` â€” full directory structure explanation
3. `3_extraction/RUNBOOK.md` â€” the current work: vertical slice through extraction

**Specs (read when working on a specific stage):**
- `0_intake/INTAKE_SPEC.md`
- `1_normalization/NORMALIZATION_SPEC_v0.5.md`
- `2_structure_discovery/STRUCTURE_SPEC.md`
- `3_atomization/ATOMIZATION_SPEC.md`
- `4_excerpting/EXCERPT_DEFINITION.md` â€” the most important spec; defines what an excerpt IS
- `4_excerpting/EXCERPTING_SPEC.md`

**Binding authority (overrides stage specs when in conflict):**
- `2_atoms_and_excerpts/00_BINDING_DECISIONS_v0.3.16.md`
- `2_atoms_and_excerpts/checklists_v0.4.md`

**Gold baselines (proven ground truth for Ø¨Ù„Ø§ØºØ©):**
- `gold_baselines/jawahir_al_balagha/passage1_v0.3.13/` â€” 21 excerpts, start here
- `3_extraction/gold/P004_gold_excerpt.json` â€” gold for Ø¥Ù…Ù„Ø§Ø¡ extraction

**Taxonomy:**
- `taxonomy/imlaa_v0.1.yaml` â€” Ø¥Ù…Ù„Ø§Ø¡ taxonomy (44 leaves), built from Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¡
- `gold_baselines/jawahir_al_balagha/passage1_v0.3.13/` contains balagha taxonomy snapshots

## Architecture Patterns

**Stage I/O chain:** Each stage reads the previous stage's JSONL output. Books are registered in `books/` with `intake_metadata.json`. Normalization produces `pages.jsonl`. Structure discovery produces `passages.jsonl` + `divisions.json`. Extraction produces `atoms` + `excerpts` per passage.

**LLM calls:** Tools call Claude/OpenAI APIs directly via httpx. API key passed as CLI arg or env var `ANTHROPIC_API_KEY`. LLM-dependent stages gracefully degrade if API fails mid-run (e.g., Stage 2 Pass 3b uses whatever Pass 3a produced).

**Validation:** Each tool has built-in validation. Extraction validates 6 invariants (atom coverage, reference integrity, leaf placement, etc.). Structure discovery validates range monotonicity, overlap, coverage.

**Testing:** pytest, no fixtures framework. Tests are self-contained with inline data. Test files mirror tool files: `test_normalization.py` tests `normalize_shamela.py`.

**Text handling:** All Arabic text is verbatim â€” never corrected, never normalized in the primary representation. A separate `normalized_text` field exists for search/matching. Diacritics preserved exactly as source.

## Code Conventions

- Python 3.11+, type hints used but not enforced
- CLI tools use argparse, not click
- JSONL for data, YAML for taxonomy, JSON for metadata
- Markdown for human review reports
- All tools are standalone scripts in `tools/`, importable as modules
- Test with `python -m pytest`, not `pytest` directly (ensures correct path)

## Current State and What to Work On

The vertical slice through Stages 3+4 proved the pipeline works end-to-end on Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¡. Two passages extracted successfully with correct taxonomy placement.

**Immediate priorities (in order):**
1. Run full book extraction (46 passages, ~$1.50) and review quality
2. Fix the 2 minor prompt issues found in testing (placeholder atoms, coverage gaps)
3. Write tests for `extract_passages.py`
4. Build Stage 6: take excerpts at one taxonomy leaf â†’ synthesize an encyclopedia entry
5. Run the pipeline on Ø´Ø°Ø§ Ø§Ù„Ø¹Ø±Ù (ØµØ±Ù science) to test cross-science generalization

**Do NOT spend time on:**
- Perfecting Stage 2 edge cases (600+ heading chunking, structureless books, etc.) â€” wait until a book actually needs them
- Multi-judge consensus â€” single-pass extraction quality is sufficient for now
- Building review UIs â€” markdown review reports are good enough

## Registered Books

```
books/
â”œâ”€â”€ imla/          # Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¡ (77p, Ø¥Ù…Ù„Ø§Ø¡) â€” vertical slice target
â”œâ”€â”€ shadha/        # Ø´Ø°Ø§ Ø§Ù„Ø¹Ø±Ù (187p, ØµØ±Ù) â€” next test target
â”œâ”€â”€ jawahir/       # Ø¬ÙˆØ§Ù‡Ø± Ø§Ù„Ø¨Ù„Ø§ØºØ© (Ø¨Ù„Ø§ØºØ©) â€” gold baseline source
â”œâ”€â”€ qatr/          # Ù‚Ø·Ø± Ø§Ù„Ù†Ø¯Ù‰ (Ù†Ø­Ùˆ)
â”œâ”€â”€ ibn_aqil/      # Ø´Ø±Ø­ Ø§Ø¨Ù† Ø¹Ù‚ÙŠÙ„ (Ù†Ø­Ùˆ)
â”œâ”€â”€ miftah/        # Ù…ÙØªØ§Ø­ Ø§Ù„Ø¹Ù„ÙˆÙ… (Ø¨Ù„Ø§ØºØ©)
â”œâ”€â”€ dalail/        # Ø¯Ù„Ø§Ø¦Ù„ Ø§Ù„Ø¥Ø¹Ø¬Ø§Ø² (Ø¨Ù„Ø§ØºØ©)
â””â”€â”€ Other Books/   # Raw Shamela exports (not yet intaked)
```

## Gotchas

- **Shamela HTML is uniform**: All 788 files use the same template. No structural variants.
- **Page numbering**: Multi-volume books may restart numbering per volume or use continuous pagination. `seq_index` is always monotonic.
- **Binding decisions override specs**: If `00_BINDING_DECISIONS_v0.3.16.md` says X and a stage spec says Y, binding decisions win.
- **Gold baselines are for Ø¨Ù„Ø§ØºØ© only**: The jawahir baselines are hand-crafted for Ø¨Ù„Ø§ØºØ©. Ø¥Ù…Ù„Ø§Ø¡ has a simpler discourse structure (rules + examples, minimal scholarly disputes).
- **`__overview` leaves**: Parent taxonomy nodes that receive overview/framing content need `__overview` companion leaves (convention from the vertical slice).
- **Passage boundaries are guidance**: Stage 2 passages are structural suggestions. Extraction may find content that spans passage boundaries (prose_tail detection handles this).
