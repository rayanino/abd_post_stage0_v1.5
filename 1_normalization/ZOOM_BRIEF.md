# Stage 1: Normalization — Zoom-In Brief

## Mandate

This is the most mature stage — existing tooling (`normalize_shamela.py`, ~1120 lines) and a detailed spec (`NORMALIZATION_SPEC_v0.5.md`) already exist, validated against 1,046 files.

## Document Relationship

There are **two spec files** in this folder:

- **`NORMALIZATION_SPEC.md`** (108 lines) — Stage-level overview. References v0.2 for details. Read this first for orientation.
- **`NORMALIZATION_SPEC_v0.2.md`** (342 lines) — The detailed transformation spec with all rules. This is the authoritative technical reference.

The overview is not a replacement for v0.2 — they serve different purposes (navigation vs. complete rules).

## Pre-Identified Issues

1. **Gold sample validation gap.** Gold samples exist (`gold_samples/`) for جواهر only. TODO-004 flags that شذا العرف (a صرف book with different patterns like "ن" footnotes) has not been validated. TODO-017 flags that additional HTML exports are needed for broader testing.

2. **Output format vs. downstream expectations.** The spec defines `pages.jsonl` as the output. Stage 2 (Structure Discovery) expects `pages.jsonl` as input. Verify the field names and types match exactly. In particular, the `headings` array structure in Stage 1 output must be compatible with Stage 2 Pass 1 (HTML-tagged headings extraction).

3. **The `book_review.md` output.** Listed in §4.3 but sparsely described. Is this generated by the normalizer? Is there a template? Is it needed for the automated pipeline or only for human review?

4. **Multi-volume stitching.** §7 mentions `global_seq` for continuous page ordering across volumes, but the current `pages.jsonl` schema doesn't include this field. Need to verify if this is implemented in the normalizer.

5. **Table extraction (v0.2 §4.10) and image-only page detection (v0.2 §4.11).** These are "new in v0.2" but their implementation status in the normalizer is unclear.

6. **Relationship to CP1 in gold baselines.** The gold baselines use `tools/extract_clean_input.py` for Checkpoint 1 (extracting clean text from HTML). This tool operates on the raw HTML, not on `pages.jsonl`. Question: in the automated pipeline, does CP1 use `pages.jsonl` output, or does it also go back to raw HTML? If the former, the normalization output must preserve enough structure for layer separation.

## What to Read

- `1_normalization/NORMALIZATION_SPEC.md` (overview)
- `1_normalization/NORMALIZATION_SPEC_v0.2.md` (detailed rules)
- `1_normalization/SHAMELA_HTML_REFERENCE.md` (HTML format documentation)
- `1_normalization/CORPUS_SURVEY_REPORT.md` (1,046-file findings)
- `1_normalization/gold_samples/` (jawahir gold output)
- `tools/normalize_shamela.py` (existing implementation)
- `tools/extract_clean_input.py` (CP1 extractor — downstream consumer of normalization)

## Expected Deliverables

- Reconciled spec (either merge the two files or add a clear header in each explaining the relationship)
- Verified field-level compatibility with Stage 2 input expectations
- Updated open questions / TODO entries
- Assessment of normalizer coverage for non-بلاغة books
